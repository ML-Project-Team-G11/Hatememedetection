# Multimodal Learning - Hate Meme Detection
This repository is used contains artifacts and codes of the ML701 capstone project at MBZUAI. 


### Overview
<p>
  Multi-modal learning aims to build models that can process and relate information from multiple modalities. Hateful memes are a recent trend of spreading hate speech on social platforms. They can be in form of videos or images that usually include text which is sarcastic or directly promotes and spreads hate, normalisation of divisiveness, and justification of violence. The hate in a meme is conveyed through both the image and the text; therefore, these two modalities need to be considered, as singularly analyzing embedded text or images will lead to inaccurate identification.
</p>

## Steps to Run

1. Install clip by running `pip install git+https://github.com/ML-Project-Team-G11/CLIP.git`
2. Run `python main.py` from the base directory.
