{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[GitHub]reproduce_submissions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kE9_rJZfF_Rf",
        "rna7NAZtwaod",
        "FyX6Qos3Olyg",
        "LzAxev4zeXxx",
        "0CTm-rxS0e97",
        "OJ19s6lUiL9w",
        "6ZyV2LQGAgB1",
        "R12C8XkYBA3q",
        "o-HsThAZBCCe",
        "CBhK1UPCcLCd",
        "F8zO7Tj98Nfp",
        "VPz2PsmU8jU-",
        "FAK66Ottxdwv"
      ],
      "mount_file_id": "1HNideFb4A7rIsX2WK3dbxnQAi7t8nq5r",
      "authorship_tag": "ABX9TyMmOg/Y+v6xA5Fp5o9hDlgL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizavelioglu/hateful_memes-hate_detectron/blob/main/notebooks/%5BGitHub%5Dreproduce_submissions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnbmxkjqXDNy"
      },
      "source": [
        "# <font color='Aqua'> <b> Team HateDetectron - Phase-2 Submissions </b> </font>\n",
        "\n",
        "---\n",
        "This notebook is only for reproducing the results of Phase-2 submissions by the team `HateDetectron`. In other words, just loading the final models and getting predictions for the test set. See the [end2end-process notebook](https://colab.research.google.com/drive/1O0m0j9_NBInzdo3K04jD19IyOhBR1I8i?usp=sharing) to see the whole approach in detail: how the models are trained, how the image features are extracted, which datasets are used, etc.\n",
        "\n",
        "---\n",
        "**Author:**\\\n",
        "<font color='Wheat'>\n",
        "    <b>\n",
        "        Riza Velioglu\n",
        "    </b>\n",
        "</font>\n",
        "\n",
        "**Contact:**\n",
        "\n",
        "<center>\n",
        "<a href=\"http://rizavelioglu.github.io/\"><img src=\"https://drive.google.com/uc?id=1SWc-ryZf7xxZ_g7AdU_vn2Y451IcCisw\" width=\"200\"></a>\n",
        "\n",
        "[Webpage](http://rizavelioglu.github.io/)\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pruHlZCZht3p",
        "cellView": "form"
      },
      "source": [
        "#@markdown ---\n",
        "#@title <h1><b> <font color='lightblue'> Running the whole notebook at once! </font> <font color='red'> --Action required!-- </b></font></h1> { run: \"auto\" }\n",
        "#@markdown Please download the `Hateful Memes Dataset` from the official challenge webpage: https://hatefulmemeschallenge.com/#download. \n",
        "#@markdown <br> After filling the form the `hateful_memes.zip` file will be downloaded, which includes all the required data including images. \n",
        "#@markdown <br><br>Please define the following variables:\n",
        "#@markdown - `PATH_TO_ZIP_FILE`: the full path of the downloaded `.zip` file. **e.g.** `\"/content/drive/MyDrive/hateful_memes.zip\"`\n",
        "#@markdown - `HOME`: the home directory of the computer. **e.g.**\n",
        "#@markdown  For <font color='orange'> Linux </font> users it can be: `\"/home/project_folder\"`. For <font color='yellow'> Colab </font> it would be: `\"/content\"`\n",
        "\n",
        "\n",
        "PATH_TO_ZIP_FILE = '' #@param {type:\"string\"}\n",
        "HOME = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Then run all the cells:\n",
        "#@markdown - <font color='yellow'> Colab </font>: **\"Runtime\" > \"Run All\"** *OR* `Ctrl+F9`\n",
        "#@markdown - <font color='orange'> Jupyter Notebook </font>: **\"Cell\" > \"Run All\"**\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-oZg0MPdTPu"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "<details><summary>\n",
        "<font color='Tan'> I. Installation of MMF & dependencies </font></summary>\n",
        "\n",
        "- install MMF dependencies\n",
        "- install MMF from source\n",
        "</details>\n",
        "\n",
        "<details><summary>\n",
        "<font color='Tan'> II. Download the dataset & convert it into MMF format </font></summary>\n",
        "\n",
        "- download Hateful Memes (HM) dataset\n",
        "- convert HM into MMF format (unzip and place the dataset to a specific location)\n",
        "- remove unnecessary data to keep the disk clean\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>\n",
        "<font color='Tan'> III. Feature Extraction </font></summary>\n",
        "\n",
        "- download image features (.zip files) for 2 datasets:  HM and [Memotion](https://www.kaggle.com/williamscott701/memotion-dataset-7k) [( see paper )](https://arxiv.org/pdf/2008.03781.pdf)\n",
        "- extract the two `.zip` files and merge them into one folder\n",
        "</details>\n",
        "\n",
        "<details><summary>\n",
        "<font color='Tan'> IV. Validating'fine-tuned' VisualBERT models on `dev_unseen.jsonl` </font></summary>\n",
        "\n",
        "- download fine-tuned models that were used in Phase-2 submission\n",
        "- evaluate them on 'dev_unseen' data\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>\n",
        "<font color='Tan'> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </font></summary>\n",
        "\n",
        "- generate predictions for 2 submissions in Phase-2\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE9_rJZfF_Rf"
      },
      "source": [
        "## <font color='magenta'> <b> I. Installation of MMF & dependencies </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ATqmsZVmEhXc",
        "outputId": "893bb3fc-debc-4402-b440-a5c8de083448"
      },
      "source": [
        "import os\n",
        "os.chdir(HOME)\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JeJ7JdvoKPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63c6df2-db1d-40e9-c7de-442bdcd2c11e"
      },
      "source": [
        "# Install specified versions of `torch` and `torchvision`, before installing mmf (causes an issue)\n",
        "!pip install torch==1.6.0 torchvision==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.6.0%2Bcu92-cp37-cp37m-linux_x86_64.whl (552.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 552.8 MB 4.3 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.7.0%2Bcu92-cp37-cp37m-linux_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0+cu92 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0+cu92 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0+cu92 torchvision-0.7.0+cu92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rna7NAZtwaod"
      },
      "source": [
        "#### *Install MMF from source* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtyIgblgvdoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9dd1ff-9df1-49d5-cf2a-ddd8e3484df3"
      },
      "source": [
        "# Clone the following repo where mmf does not install default image features, \n",
        "# since we will use our own features\n",
        "!git clone --branch no_feats --config core.symlinks=true https://github.com/rizavelioglu/mmf.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmf'...\n",
            "remote: Enumerating objects: 16730, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 16730 (delta 1), reused 2 (delta 0), pack-reused 16724\u001b[K\n",
            "Receiving objects: 100% (16730/16730), 12.79 MiB | 10.11 MiB/s, done.\n",
            "Resolving deltas: 100% (10763/10763), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHzXv9ogv3K8"
      },
      "source": [
        "os.chdir(os.path.join(HOME, \"mmf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eVZPra-wMgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87a2971-bf00-4e43-8f45-2c7b292a8974"
      },
      "source": [
        "!pip install --editable ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/mmf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.21.6)\n",
            "Collecting GitPython==3.1.0\n",
            "  Downloading GitPython-3.1.0-py3-none-any.whl (450 kB)\n",
            "\u001b[K     |████████████████████████████████| 450 kB 17.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.5.3)\n",
            "Collecting torchtext==0.5.0\n",
            "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.1.0)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (4.64.0)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.6.0+cu92)\n",
            "Collecting demjson==2.2.4\n",
            "  Downloading demjson-2.2.4.tar.gz (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.23.0)\n",
            "Collecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 41.6 MB/s \n",
            "\u001b[?25hCollecting fasttext==0.9.1\n",
            "  Downloading fasttext-0.9.1.tar.gz (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.7.0+cu92)\n",
            "Collecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 40.6 MB/s \n",
            "\u001b[?25hCollecting lmdb==0.98\n",
            "  Downloading lmdb-0.98.tar.gz (869 kB)\n",
            "\u001b[K     |████████████████████████████████| 869 kB 46.3 MB/s \n",
            "\u001b[?25hCollecting omegaconf==2.0.1rc4\n",
            "  Downloading omegaconf-2.0.1rc4-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.0)\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf==1.0.0rc12) (57.4.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->mmf==1.0.0rc12) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.1rc4->mmf==1.0.0rc12) (4.1.1)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (3.0.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->mmf==1.0.0rc12) (1.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->mmf==1.0.0rc12) (0.16.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0->mmf==1.0.0rc12) (7.1.2)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.17.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 64.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->mmf==1.0.0rc12) (3.0.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0->mmf==1.0.0rc12) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0->mmf==1.0.0rc12) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (1.4.1)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'omegaconf' candidate (version 2.0.1rc4 at https://files.pythonhosted.org/packages/03/c6/dec84d1b2a3d645f03201dca03bc879b6116cb6503449a31d7ff9c1394a4/omegaconf-2.0.1rc4-py3-none-any.whl#sha256=e04462f7e3d8f51532221471b241f67e35a36a04e364c70987018faadd273cc0 (from https://pypi.org/simple/omegaconf/) (requires-python:>=3.6))\n",
            "Reason for being yanked: <none given>\u001b[0m\n",
            "Building wheels for collected packages: demjson, fasttext, lmdb, nltk\n",
            "  Building wheel for demjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demjson: filename=demjson-2.2.4-py3-none-any.whl size=73565 sha256=fedb687221a42c18e3e006990359cbcc0d8350c3efa9cd40ec51a9fc9e307514\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/94/3d/466801f4a8db8e6fce765d7a0115dfebcc55ddf6b00cd98f59\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp37-cp37m-linux_x86_64.whl size=2504244 sha256=c18204a518a4dde0a7e8e5594b9cf4e8aa9ac206a4ddbe1882d89672dcf1ad5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/5b/4b/9c582c778bb93aaad8fc855d5e79f49eae34f59e363a22c422\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lmdb: filename=lmdb-0.98-cp37-cp37m-linux_x86_64.whl size=219750 sha256=51ee0ec690c1dcfbddcb5a6ad10ad8a590a115f541c769aae507f15cb425eeb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/24/96/783d4dddcf63e3f8cc92db8b3af3c70cf6d76398bff77f1d5e\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449925 sha256=aa7a1a6b96add059c3654d5bc48bffeaa2a284d0f52f923dca668814e327a822\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built demjson fasttext lmdb nltk\n",
            "Installing collected packages: smmap, tokenizers, sentencepiece, sacremoses, PyYAML, pybind11, gitdb, transformers, torchtext, omegaconf, nltk, lmdb, GitPython, fasttext, demjson, mmf\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: lmdb\n",
            "    Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "  Running setup.py develop for mmf\n",
            "Successfully installed GitPython-3.1.0 PyYAML-6.0 demjson-2.2.4 fasttext-0.9.1 gitdb-4.0.9 lmdb-0.98 mmf nltk-3.4.5 omegaconf-2.0.1rc4 pybind11-2.9.2 sacremoses-0.0.49 sentencepiece-0.1.96 smmap-5.0.0 tokenizers-0.9.2 torchtext-0.5.0 transformers-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyX6Qos3Olyg"
      },
      "source": [
        "---\n",
        "## <font color='magenta'> <b> II. Download the dataset & convert it into *MMF* format </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvK9KdbloYZJ"
      },
      "source": [
        "!cp $PATH_TO_ZIP_FILE /content/mmf/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the mmf folder to Python Path\n",
        "os.environ['PYTHONPATH'] += \":/content/mmf/\""
      ],
      "metadata": {
        "id": "xIED0Rxpv39Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_convert_hm --zip_file=\"hateful_memes.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5boYN-8lv5Cw",
        "outputId": "ac6e02ae-ed87-41d7-e619-ba76df5595b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data folder is /root/.cache/torch/mmf/data\n",
            "Zip path is hateful_memes.zip\n",
            "Copying hateful_memes.zip\n",
            "Unzipping hateful_memes.zip\n",
            "Extracting the zip can take time. Sit back and relax.\n",
            "Moving train.jsonl\n",
            "Moving dev_seen.jsonl\n",
            "Moving test_seen.jsonl\n",
            "Moving dev_unseen.jsonl\n",
            "Moving test_unseen.jsonl\n",
            "Moving img\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKUDTNzLxvXf"
      },
      "source": [
        "# Free up the disk by removing .zip, .tar files\n",
        "!rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/hateful_memes.zip\n",
        "!rm -rf $HOME/mmf/hateful_memes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzAxev4zeXxx"
      },
      "source": [
        "---\n",
        "## <font color='magenta'> <b> III. Feature Extraction </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CTm-rxS0e97"
      },
      "source": [
        "### <font color='lightgreen'> <b> Collect 'pre-extracted' features </b> </font>\n",
        "\n",
        "There are 2 .zip files which stores the extracted image features: one for <font color='Salmon'>Hateful Memes</font>, and one for <font color='Salmon'> Memotion Dataset</font>.\n",
        "\n",
        "The following cell downloads both .zip files into the `$HOME` directory:\n",
        "- [hateful_memes_features](https://drive.google.com/file/d/1YGigTCQQlVvS726YuECTMx0He8p0Xle2/view?usp=sharing)\n",
        "- [memotion_features](https://drive.google.com/file/d/11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(HOME)\n",
        "# download HM dataset features\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YGigTCQQlVvS726YuECTMx0He8p0Xle2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1YGigTCQQlVvS726YuECTMx0He8p0Xle2\" -O 'feats_hm.zip' && rm -rf /tmp/cookies.txt\n",
        "# download Memotion dataset features\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a\" -O 'feats_memotion.zip' && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltqR68Ku2nBe",
        "outputId": "9d270822-6321-41fe-ab17-31e990400f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 16:00:34--  https://docs.google.com/uc?export=download&confirm=t&id=1YGigTCQQlVvS726YuECTMx0He8p0Xle2\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.12.138, 142.251.12.139, 142.251.12.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.12.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-6o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4uh0p4j60kjoqe34jutld88ejbqhg1l7/1650556800000/15631633617501527889/*/1YGigTCQQlVvS726YuECTMx0He8p0Xle2?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-21 16:00:34--  https://doc-0o-6o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4uh0p4j60kjoqe34jutld88ejbqhg1l7/1650556800000/15631633617501527889/*/1YGigTCQQlVvS726YuECTMx0He8p0Xle2?e=download\n",
            "Resolving doc-0o-6o-docs.googleusercontent.com (doc-0o-6o-docs.googleusercontent.com)... 74.125.68.132, 2404:6800:4003:c02::84\n",
            "Connecting to doc-0o-6o-docs.googleusercontent.com (doc-0o-6o-docs.googleusercontent.com)|74.125.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10242100950 (9.5G) [application/zip]\n",
            "Saving to: ‘feats_hm.zip’\n",
            "\n",
            "feats_hm.zip        100%[===================>]   9.54G  65.8MB/s    in 2m 49s  \n",
            "\n",
            "2022-04-21 16:03:25 (57.7 MB/s) - ‘feats_hm.zip’ saved [10242100950/10242100950]\n",
            "\n",
            "--2022-04-21 16:03:25--  https://docs.google.com/uc?export=download&confirm=t&id=11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.10.138, 142.251.10.100, 142.251.10.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.10.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-6o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/g7j7665nmd4b4q9ff9fg65poj9u0eigp/1650556950000/15631633617501527889/*/11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-21 16:03:25--  https://doc-0s-6o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/g7j7665nmd4b4q9ff9fg65poj9u0eigp/1650556950000/15631633617501527889/*/11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a?e=download\n",
            "Resolving doc-0s-6o-docs.googleusercontent.com (doc-0s-6o-docs.googleusercontent.com)... 74.125.68.132, 2404:6800:4003:c02::84\n",
            "Connecting to doc-0s-6o-docs.googleusercontent.com (doc-0s-6o-docs.googleusercontent.com)|74.125.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 201908855 (193M) [application/zip]\n",
            "Saving to: ‘feats_memotion.zip’\n",
            "\n",
            "feats_memotion.zip  100%[===================>] 192.55M  43.0MB/s    in 4.5s    \n",
            "\n",
            "2022-04-21 16:03:31 (43.0 MB/s) - ‘feats_memotion.zip’ saved [201908855/201908855]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip features for Memotion dataset & remove it to free disk\n",
        "!unzip -q $HOME/feats_memotion.zip -d $HOME/features/\n",
        "!rm -rf $HOME/feats_memotion.zip\n",
        "# Unzip features for HM dataset & remove it to free disk\n",
        "!unzip -q $HOME/feats_hm.zip -d $HOME/features/\n",
        "!rm -rf $HOME/feats_hm.zip\n",
        "# Move Memotion features into the same folder as HM features\n",
        "!mv $HOME/features/feats_memotion/*.npy $HOME/features/feats_hm/"
      ],
      "metadata": {
        "id": "NLQvkALw3WVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ19s6lUiL9w"
      },
      "source": [
        "---\n",
        "## <font color='magenta'> <b> IV. Validating'fine-tuned' VisualBERT models on `dev_unseen.jsonl`</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZyV2LQGAgB1"
      },
      "source": [
        "### <font color='Violet'> <b> Submission#1 </b> </font>\n",
        "\n",
        "|            | ROC-AUC | Accuracy |    Dataset   |\n",
        "|------------|:-------:|:--------:|:------------:|\n",
        "|Submission#1| $0.7555$| $0.7352$ | `dev_unseen` |\n",
        "|Submission#1| $0.8108$| $0.7650$ | `test_unseen`|\n",
        "\n",
        "The following cell downloads the fine-tuned model from [this link](https://drive.google.com/file/d/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2/view?usp=sharing) to the `$HOME` directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi3fDczdwSTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4d2872-25c3-4735-c22d-d2f6d690f6f0"
      },
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# os.chdir(HOME)\n",
        "# # Download the fine-tuned model\n",
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2\" -O 'submission#1.zip' && rm -rf /tmp/cookies.txt\n",
        "# # unzip the model\n",
        "# !unzip -qq $HOME/submission#1.zip -d $HOME/submission#1\n",
        "# # remove the .zip after unzipping to free the disk\n",
        "# !rm -rf $HOME/submission#1.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-01 11:52:08--  https://docs.google.com/uc?export=download&confirm=bgVo&id=1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.2.110, 2607:f8b0:4004:80a::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.2.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-8k-docs.googleusercontent.com/docs/securesc/v8qt23aghtn6s5u56li7348eoei3pipj/0s788egsk8ukafuun5kffq6q4q0pi94i/1606823475000/15631633617501527889/17850159486476952229Z/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2?e=download [following]\n",
            "--2020-12-01 11:52:08--  https://doc-0c-8k-docs.googleusercontent.com/docs/securesc/v8qt23aghtn6s5u56li7348eoei3pipj/0s788egsk8ukafuun5kffq6q4q0pi94i/1606823475000/15631633617501527889/17850159486476952229Z/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2?e=download\n",
            "Resolving doc-0c-8k-docs.googleusercontent.com (doc-0c-8k-docs.googleusercontent.com)... 172.217.15.65, 2607:f8b0:4004:810::2001\n",
            "Connecting to doc-0c-8k-docs.googleusercontent.com (doc-0c-8k-docs.googleusercontent.com)|172.217.15.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=ro8ubvop6cehm&continue=https://doc-0c-8k-docs.googleusercontent.com/docs/securesc/v8qt23aghtn6s5u56li7348eoei3pipj/0s788egsk8ukafuun5kffq6q4q0pi94i/1606823475000/15631633617501527889/17850159486476952229Z/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2?e%3Ddownload&hash=m1vomnblu11kr4rt7vddpug8d70jvmu5 [following]\n",
            "--2020-12-01 11:52:08--  https://docs.google.com/nonceSigner?nonce=ro8ubvop6cehm&continue=https://doc-0c-8k-docs.googleusercontent.com/docs/securesc/v8qt23aghtn6s5u56li7348eoei3pipj/0s788egsk8ukafuun5kffq6q4q0pi94i/1606823475000/15631633617501527889/17850159486476952229Z/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2?e%3Ddownload&hash=m1vomnblu11kr4rt7vddpug8d70jvmu5\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.2.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0c-8k-docs.googleusercontent.com/docs/securesc/v8qt23aghtn6s5u56li7348eoei3pipj/0s788egsk8ukafuun5kffq6q4q0pi94i/1606823475000/15631633617501527889/17850159486476952229Z/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2?e=download&nonce=ro8ubvop6cehm&user=17850159486476952229Z&hash=f47jo160ro3l2o1o3j7v48ffi4r1m6cv [following]\n",
            "--2020-12-01 11:52:08--  https://doc-0c-8k-docs.googleusercontent.com/docs/securesc/v8qt23aghtn6s5u56li7348eoei3pipj/0s788egsk8ukafuun5kffq6q4q0pi94i/1606823475000/15631633617501527889/17850159486476952229Z/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2?e=download&nonce=ro8ubvop6cehm&user=17850159486476952229Z&hash=f47jo160ro3l2o1o3j7v48ffi4r1m6cv\n",
            "Connecting to doc-0c-8k-docs.googleusercontent.com (doc-0c-8k-docs.googleusercontent.com)|172.217.15.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘submission#1.zip’\n",
            "\n",
            "submission#1.zip        [        <=>         ]   1.03G  92.6MB/s    in 12s     \n",
            "\n",
            "2020-12-01 11:52:20 (91.1 MB/s) - ‘submission#1.zip’ saved [1108315403]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDfafzqZ58iF",
        "outputId": "09b3f01d-50d5-487c-d825-31bccf38c9e9"
      },
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# # Validate the model on the dev_unseen data\n",
        "# os.chdir(HOME)\n",
        "# # where checkpoint is\n",
        "# ckpt_dir = os.path.join(HOME, \"submission#1/best.ckpt\")\n",
        "# feats_dir = os.path.join(HOME, \"features/feats_hm\")\n",
        "\n",
        "# !mmf_run config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
        "#     model=\"visual_bert\" \\\n",
        "#     dataset=hateful_memes \\\n",
        "#     run_type=val \\\n",
        "#     checkpoint.resume_file=$ckpt_dir \\\n",
        "#     checkpoint.reset.optimizer=True \\\n",
        "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-26 14:15:02.201805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
            "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
            "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
            "  warnings.warn(message=msg, category=UserWarning)\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/visual_bert/configs/hateful_memes/defaults.yaml\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option run_type to val\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to /content/submission#1/best.ckpt\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.reset.optimizer to True\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_unseen.jsonl\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_unseen.jsonl\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.train[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.val[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.test[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf: \u001b[0mLogging to: ./save/train.log\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=/content/submission#1/best.ckpt', 'checkpoint.reset.optimizer=True', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl', 'dataset_config.hateful_memes.features.train[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.val[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.test[0]=/content/features/feats_hm'])\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf_cli.run: \u001b[0mTorch version: 1.6.0+cu92\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla K80\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf_cli.run: \u001b[0mUsing seed 5419996\n",
            "\u001b[32m2020-11-26T14:15:05 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "\u001b[32m2020-11-26T14:15:12 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2020-11-26T14:15:19 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2020-11-26T14:15:19 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2020-11-26T14:15:19 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:15:20 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:15:20 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:15:20 | mmf.utils.checkpoint: \u001b[0mMissing keys ['model.bert.embeddings.position_ids'] in the checkpoint.\n",
            "If this is not your checkpoint, please open up an issue on MMF GitHub. \n",
            "Unexpected keys if any: []\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:15:20 | py.warnings: \u001b[0m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:15:20 | py.warnings: \u001b[0m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2800\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2800\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 10\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2020-11-26T14:15:20 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on val set\n",
            "100% 9/9 [00:19<00:00,  2.15s/it]\n",
            "\u001b[32m2020-11-26T14:15:39 | mmf.trainers.callbacks.logistics: \u001b[0mval/hateful_memes/cross_entropy: 1.0861, val/total_loss: 1.0861, val/hateful_memes/accuracy: 0.7352, val/hateful_memes/binary_f1: 0.5994, val/hateful_memes/roc_auc: 0.7568\n",
            "\u001b[32m2020-11-26T14:15:39 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 20s 259ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R12C8XkYBA3q"
      },
      "source": [
        "### <font color='Violet'> <b> Submission#2 </b> </font>\n",
        "\n",
        "|            | ROC-AUC | Accuracy |    Dataset   |\n",
        "|------------|:-------:|:--------:|:------------:|\n",
        "|Submission#2| $0.7757$| $0.7315$ | `dev_unseen` |\n",
        "|Submission#2| $0.8268$| $0.7805$ | `test_unseen`|\n",
        "\n",
        "The following cell downloads the fine-tuned model from [this link](https://drive.google.com/file/d/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB/view?usp=sharing) to the `$HOME` directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipPVBLRtwtgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd657d54-f431-4f99-8546-5678f656e017"
      },
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# os.chdir(HOME)\n",
        "# # Download the fine-tuned model\n",
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1To4L0on-Us-DHFn53b21lYYcl6RgaDCB' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1To4L0on-Us-DHFn53b21lYYcl6RgaDCB\" -O 'submission#2.zip' && rm -rf /tmp/cookies.txt\n",
        "# # Unzip the model\n",
        "# !unzip -q $HOME/submission#2.zip -d $HOME/submission#2\n",
        "# # remove the .zip after unzipping to free the disk\n",
        "# !rm -rf $HOME/submission#2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-01 12:09:50--  https://docs.google.com/uc?export=download&confirm=G9D8&id=1To4L0on-Us-DHFn53b21lYYcl6RgaDCB\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.2.110, 2607:f8b0:4004:80a::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.2.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-ac-docs.googleusercontent.com/docs/securesc/p2koco7jmelk51cclteicg7jkiakppuc/7qt6bevk35a4fhu1thg5pa1slplt4n9n/1606824525000/15631633617501527889/08426210042794117368Z/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB?e=download [following]\n",
            "--2020-12-01 12:09:50--  https://doc-14-ac-docs.googleusercontent.com/docs/securesc/p2koco7jmelk51cclteicg7jkiakppuc/7qt6bevk35a4fhu1thg5pa1slplt4n9n/1606824525000/15631633617501527889/08426210042794117368Z/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB?e=download\n",
            "Resolving doc-14-ac-docs.googleusercontent.com (doc-14-ac-docs.googleusercontent.com)... 172.217.15.65, 2607:f8b0:4004:810::2001\n",
            "Connecting to doc-14-ac-docs.googleusercontent.com (doc-14-ac-docs.googleusercontent.com)|172.217.15.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=tugrj8f2ud9c6&continue=https://doc-14-ac-docs.googleusercontent.com/docs/securesc/p2koco7jmelk51cclteicg7jkiakppuc/7qt6bevk35a4fhu1thg5pa1slplt4n9n/1606824525000/15631633617501527889/08426210042794117368Z/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB?e%3Ddownload&hash=0upgki49u9g8npf5hk3cse972qn5g5q5 [following]\n",
            "--2020-12-01 12:09:50--  https://docs.google.com/nonceSigner?nonce=tugrj8f2ud9c6&continue=https://doc-14-ac-docs.googleusercontent.com/docs/securesc/p2koco7jmelk51cclteicg7jkiakppuc/7qt6bevk35a4fhu1thg5pa1slplt4n9n/1606824525000/15631633617501527889/08426210042794117368Z/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB?e%3Ddownload&hash=0upgki49u9g8npf5hk3cse972qn5g5q5\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.2.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-14-ac-docs.googleusercontent.com/docs/securesc/p2koco7jmelk51cclteicg7jkiakppuc/7qt6bevk35a4fhu1thg5pa1slplt4n9n/1606824525000/15631633617501527889/08426210042794117368Z/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB?e=download&nonce=tugrj8f2ud9c6&user=08426210042794117368Z&hash=vvjbp6mea1tbbb2skpbsqq5m3iopvumf [following]\n",
            "--2020-12-01 12:09:50--  https://doc-14-ac-docs.googleusercontent.com/docs/securesc/p2koco7jmelk51cclteicg7jkiakppuc/7qt6bevk35a4fhu1thg5pa1slplt4n9n/1606824525000/15631633617501527889/08426210042794117368Z/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB?e=download&nonce=tugrj8f2ud9c6&user=08426210042794117368Z&hash=vvjbp6mea1tbbb2skpbsqq5m3iopvumf\n",
            "Connecting to doc-14-ac-docs.googleusercontent.com (doc-14-ac-docs.googleusercontent.com)|172.217.15.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘submission#2.zip’\n",
            "\n",
            "submission#2.zip        [          <=>       ]   1.03G   100MB/s    in 12s     \n",
            "\n",
            "2020-12-01 12:10:03 (90.4 MB/s) - ‘submission#2.zip’ saved [1107760419]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# os.chdir(HOME)\n",
        "# # where checkpoint is\n",
        "# ckpt_dir = os.path.join(HOME, \"submission#2/best.ckpt\")\n",
        "# feats_dir = os.path.join(HOME, \"features/feats_hm\")\n",
        "\n",
        "# !mmf_run config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
        "#     model=\"visual_bert\" \\\n",
        "#     dataset=hateful_memes \\\n",
        "#     run_type=val \\\n",
        "#     checkpoint.resume_file=$ckpt_dir \\\n",
        "#     checkpoint.reset.optimizer=True \\\n",
        "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FRorMhP44AY",
        "outputId": "8daa8f8b-52b8-4e6f-b74b-e32cb77d87a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
            "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
            "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
            "  warnings.warn(message=msg, category=UserWarning)\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/visual_bert/configs/hateful_memes/defaults.yaml\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option run_type to val\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to /content/submission#2/best.ckpt\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.reset.optimizer to True\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_unseen.jsonl\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_unseen.jsonl\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.train[0] to /content/features/feats_hm\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.val[0] to /content/features/feats_hm\n",
            "\u001b[32m2022-04-21T16:10:52 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.test[0] to /content/features/feats_hm\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n",
            "Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
            "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
            "If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
            "\u001b[32m2022-04-21T16:10:53 | mmf: \u001b[0mLogging to: ./save/train.log\n",
            "\u001b[32m2022-04-21T16:10:53 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=/content/submission#2/best.ckpt', 'checkpoint.reset.optimizer=True', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl', 'dataset_config.hateful_memes.features.train[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.val[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.test[0]=/content/features/feats_hm'])\n",
            "\u001b[32m2022-04-21T16:10:53 | mmf_cli.run: \u001b[0mTorch version: 1.6.0+cu92\n",
            "\u001b[32m2022-04-21T16:10:53 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla T4\n",
            "\u001b[32m2022-04-21T16:10:53 | mmf_cli.run: \u001b[0mUsing seed 53059841\n",
            "\u001b[32m2022-04-21T16:10:53 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:01<00:00, 132kB/s]\n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "Downloading: 100% 433/433 [00:00<00:00, 388kB/s]\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 270kB/s]\n",
            "\u001b[32m2022-04-21T16:11:03 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Downloading: 100% 440M/440M [00:09<00:00, 47.1MB/s]\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2022-04-21T16:11:21 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-04-21T16:11:21 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-04-21T16:11:21 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-21T16:11:22 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-21T16:11:22 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-21T16:11:22 | mmf.utils.checkpoint: \u001b[0mMissing keys ['model.bert.embeddings.position_ids'] in the checkpoint.\n",
            "If this is not your checkpoint, please open up an issue on MMF GitHub. \n",
            "Unexpected keys if any: []\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-21T16:11:22 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-21T16:11:22 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 3150\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 3150\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 27\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2022-04-21T16:11:22 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on val set\n",
            "100% 9/9 [00:12<00:00,  1.41s/it]\n",
            "\u001b[32m2022-04-21T16:11:35 | mmf.trainers.callbacks.logistics: \u001b[0mval/hateful_memes/cross_entropy: 1.8660, val/total_loss: 1.8660, val/hateful_memes/accuracy: 0.7315, val/hateful_memes/binary_f1: 0.5646, val/hateful_memes/roc_auc: 0.7778\n",
            "\u001b[32m2022-04-21T16:11:35 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 13s 597ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-HsThAZBCCe"
      },
      "source": [
        "### <font color='Violet'> <b> Submission#3 ($Best\\ Submission$)</b> </font>\n",
        "\n",
        "|            | ROC-AUC | Accuracy |    Dataset   |\n",
        "|------------|:-------:|:--------:|:------------:|\n",
        "|Submission#3| $-$     | $-$      | `dev_unseen` |\n",
        "|Submission#3| $0.8518$| $0.8050$ | `test_unseen`|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZowowhGDmfvm"
      },
      "source": [
        "After a hyper-parameter search, we ended up having multiple models having different ROC-AUC scores on `dev_unseen` dataset. We sorted them by the ROC score and took all the models that have a ROC score of `0.76` or higher (the threshold is chosen arbitrarily). The following figure shows all the $27$ models and its ROC-scores, as well as its hyper-parameters ([see this document for all the model scores, 60+ models in total](https://docs.google.com/spreadsheets/d/11m2p7vNxHhZWumkFNvv6d94HcqG77DItRX7MuGfOtWA/edit?usp=sharing)).\n",
        "\n",
        "<details><summary>\n",
        "<font color='Tan'> Figure 1: ROC-AUC scores (on `dev_unseen`) of different VisualBERT models </font></summary>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=10WUBnSO5L5O44c8WCxHRA_iFZudH73lF\" width=\"1000\"> \n",
        "\n",
        "</details>\n",
        "\n",
        "Then, predictions are collected from each of the $27$ models and the `Majority Voting` technique is applied: the `class` of a data point is determined by the majority voted class.\n",
        "\n",
        "> This technique is also known as: [Voting classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html), [Ensemble learning](https://en.wikipedia.org/wiki/Ensemble_learning), [Bootstrap Aggregating (BAGGING)](https://en.wikipedia.org/wiki/Bootstrap_aggregating#:~:text=Bootstrap%20aggregating%2C%20also%20called%20bagging,and%20helps%20to%20avoid%20overfitting.)\n",
        "\n",
        "Please see [this document](https://drive.google.com/file/d/1vjUsMqaqjZdoNj0w989RX7GKkPod-CGo/view?usp=sharing) to see all the model predictions for `test_unseen` and how the technique is applied.\n",
        "\n",
        "**Note:**  The `proba` column in the submission which stands for the probability of a data point belonging to a class is chosen to be the maximum probability among all of the $27$ models if $Class\\ 1$, and the minumum if $Class\\ 0$.\n",
        "\n",
        "See the Part<font color='magenta'> <b> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </b> </font> for the code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBhK1UPCcLCd"
      },
      "source": [
        "---\n",
        "## <font color='magenta'> <b> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8zO7Tj98Nfp"
      },
      "source": [
        "### <font color='Thistle'> <b> Submission#1 </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmaeQY_GcS93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9953343-1915-4a66-b120-b42f668c9911"
      },
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# os.chdir(HOME)\n",
        "# # where checkpoint is\n",
        "# ckpt_dir = os.path.join(HOME, \"submission#1/best.ckpt\")\n",
        "# feats_dir = os.path.join(HOME, \"features/feats_hm\")\n",
        "\n",
        "# !mmf_predict config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
        "#     model=\"visual_bert\" \\\n",
        "#     dataset=hateful_memes \\\n",
        "#     run_type=test \\\n",
        "#     checkpoint.resume_file=$ckpt_dir \\\n",
        "#     checkpoint.reset.optimizer=True \\\n",
        "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-26 14:26:12.878826: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
            "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
            "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
            "  warnings.warn(message=msg, category=UserWarning)\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/visual_bert/configs/hateful_memes/defaults.yaml\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to /content/submission#1/best.ckpt\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.reset.optimizer to True\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_unseen.jsonl\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_unseen.jsonl\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.train[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.val[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.test[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf: \u001b[0mLogging to: ./save/train.log\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=/content/submission#1/best.ckpt', 'checkpoint.reset.optimizer=True', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl', 'dataset_config.hateful_memes.features.train[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.val[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.test[0]=/content/features/feats_hm', 'evaluation.predict=true'])\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf_cli.run: \u001b[0mTorch version: 1.6.0+cu92\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla K80\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf_cli.run: \u001b[0mUsing seed 16442183\n",
            "\u001b[32m2020-11-26T14:26:16 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "\u001b[32m2020-11-26T14:26:23 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2020-11-26T14:26:30 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2020-11-26T14:26:30 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2020-11-26T14:26:30 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:26:31 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:26:31 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:26:31 | mmf.utils.checkpoint: \u001b[0mMissing keys ['model.bert.embeddings.position_ids'] in the checkpoint.\n",
            "If this is not your checkpoint, please open up an issue on MMF GitHub. \n",
            "Unexpected keys if any: []\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:26:31 | py.warnings: \u001b[0m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:26:31 | py.warnings: \u001b[0m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[32m2020-11-26T14:26:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2020-11-26T14:26:31 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2800\n",
            "\u001b[32m2020-11-26T14:26:31 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2800\n",
            "\u001b[32m2020-11-26T14:26:31 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 10\n",
            "\u001b[32m2020-11-26T14:26:31 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n",
            "\u001b[32m2020-11-26T14:26:31 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 32/32 [01:27<00:00,  2.75s/it]\n",
            "\u001b[32m2020-11-26T14:27:58 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/save/hateful_memes_visual_bert_16442183/reports/hateful_memes_run_test_2020-11-26T14:27:58.csv\n",
            "\u001b[32m2020-11-26T14:27:59 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPz2PsmU8jU-"
      },
      "source": [
        "### <font color='Thistle'> <b> Submission#2 </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HR3nPRV8jU_",
        "outputId": "4d227084-48c9-4dfa-bda1-15c0e5fa567c"
      },
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# os.chdir(HOME)\n",
        "# # where checkpoint is\n",
        "# ckpt_dir = os.path.join(HOME, \"submission#2/best.ckpt\")\n",
        "# feats_dir = os.path.join(HOME, \"features/feats_hm\")\n",
        "\n",
        "# !mmf_predict config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
        "#     model=\"visual_bert\" \\\n",
        "#     dataset=hateful_memes \\\n",
        "#     run_type=test \\\n",
        "#     checkpoint.resume_file=$ckpt_dir \\\n",
        "#     checkpoint.reset.optimizer=True \\\n",
        "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-26 14:28:04.106941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/omegaconf/dictconfig.py:252: UserWarning: Keys with dot (model.bert) are deprecated and will have different semantic meaning the next major version of OmegaConf (2.1)\n",
            "See the compact keys issue for more details: https://github.com/omry/omegaconf/issues/152\n",
            "You can disable this warning by setting the environment variable OC_DISABLE_DOT_ACCESS_WARNING=1\n",
            "  warnings.warn(message=msg, category=UserWarning)\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/visual_bert/configs/hateful_memes/defaults.yaml\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to /content/submission#2/best.ckpt\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.reset.optimizer to True\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_unseen.jsonl\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_unseen.jsonl\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.train[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.val[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.features.test[0] to /content/features/feats_hm\n",
            "\u001b[32m2020-11-26T14:28:07 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n",
            "\u001b[32m2020-11-26T14:28:08 | mmf: \u001b[0mLogging to: ./save/train.log\n",
            "\u001b[32m2020-11-26T14:28:08 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=/content/submission#2/best.ckpt', 'checkpoint.reset.optimizer=True', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl', 'dataset_config.hateful_memes.features.train[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.val[0]=/content/features/feats_hm', 'dataset_config.hateful_memes.features.test[0]=/content/features/feats_hm', 'evaluation.predict=true'])\n",
            "\u001b[32m2020-11-26T14:28:08 | mmf_cli.run: \u001b[0mTorch version: 1.6.0+cu92\n",
            "\u001b[32m2020-11-26T14:28:08 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla K80\n",
            "\u001b[32m2020-11-26T14:28:08 | mmf_cli.run: \u001b[0mUsing seed 8028831\n",
            "\u001b[32m2020-11-26T14:28:08 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "\u001b[32m2020-11-26T14:28:14 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2020-11-26T14:28:21 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2020-11-26T14:28:21 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2020-11-26T14:28:21 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:28:58 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:28:58 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:28:58 | mmf.utils.checkpoint: \u001b[0mMissing keys ['model.bert.embeddings.position_ids'] in the checkpoint.\n",
            "If this is not your checkpoint, please open up an issue on MMF GitHub. \n",
            "Unexpected keys if any: []\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:28:58 | py.warnings: \u001b[0m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2020-11-26T14:28:58 | py.warnings: \u001b[0m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "\u001b[32m2020-11-26T14:28:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2020-11-26T14:28:58 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 3150\n",
            "\u001b[32m2020-11-26T14:28:58 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 3150\n",
            "\u001b[32m2020-11-26T14:28:58 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 27\n",
            "\u001b[32m2020-11-26T14:28:58 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n",
            "\u001b[32m2020-11-26T14:28:58 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 32/32 [01:27<00:00,  2.75s/it]\n",
            "\u001b[32m2020-11-26T14:30:26 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/save/hateful_memes_visual_bert_8028831/reports/hateful_memes_run_test_2020-11-26T14:30:26.csv\n",
            "\u001b[32m2020-11-26T14:30:26 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAK66Ottxdwv"
      },
      "source": [
        "### <font color='Thistle'> <b> Submission#3  ($Best\\ Submission$)</b> </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0veOdd4QYwDa",
        "outputId": "dec9dff0-8858-44b6-c046-d876d60373e1"
      },
      "source": [
        "os.mkdir(f\"{HOME}/sub3/\")\n",
        "os.chdir(os.path.join(HOME, \"sub3\"))\n",
        "!git clone https://github.com/rizavelioglu/hateful_memes-hate_detectron.git\n",
        "!cp hateful_memes-hate_detectron/utils/generate_submission.sh .\n",
        "!chmod +x generate_submission.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hateful_memes-hate_detectron'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 39 (delta 14), reused 35 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-9rsMTMYwDa"
      },
      "source": [
        "Download 27 models in a `.7z` file and extract them all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QFh5YY-YwDa"
      },
      "source": [
        "# Download the .7z file which includes all the 27 models\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1D1nehiowEHMxJwijybfuTiC1835wZaHk' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1D1nehiowEHMxJwijybfuTiC1835wZaHk\" -O 'majority_voting_models.7z' && rm -rf /tmp/cookies.txt\n",
        "# Extract the .7z file to get the models\n",
        "# !p7zip -d 'majority_voting_models.7z'\n",
        "# !sudo apt-get install p7zip-full p7zip-rar\n",
        "!7z e 'majority_voting_models.7z'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnqJyYjTYwDa"
      },
      "source": [
        "Generate submission for each model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4bF8UbJYwDa"
      },
      "source": [
        "from subprocess import call\n",
        "\n",
        "models = [i for i in os.listdir(\".\") if i.endswith(\".ckpt\")]\n",
        "\n",
        "print(f\"[INFO] Getting predictions for {len(models)} models! This might take long..\")\n",
        "for model in models:\n",
        "    feats_dir = os.path.join(HOME, \"features/feats_hm\")\n",
        "    # Execute the bash script which gets predictions for 'test_unseen' data\n",
        "    rc = call(f\"./generate_submission.sh {model} {feats_dir}\", shell=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A40AWbCuYwDa"
      },
      "source": [
        "Apply majority voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zQCkM-_YwDa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Store all the prediction folders\n",
        "folders = [i for i in os.listdir(\"save/preds\") if i.startswith(\"hateful_memes\")]\n",
        "preds = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "    for folder in folders:\n",
        "        pred = [i for i in os.listdir(f\"save/preds/{folder}/reports/\") if i.endswith(\".csv\")]\n",
        "        pred = pd.read_csv(f\"save/preds/{folder}/reports/{pred[0]}\")\n",
        "        preds = pd.concat([preds, pred], axis=1)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# assert len(preds.columns) == 27*3\n",
        "\n",
        "# Create \n",
        "submission = pred\n",
        "np_df = np.asarray(preds)\n",
        "\n",
        "for idx, row in enumerate(np_df[:,:]):\n",
        "    probas = row[1::3]\n",
        "    labels = row[2::3]\n",
        "\n",
        "    if sum(labels) > 13:\n",
        "        submission.loc[idx, 'label']=1\n",
        "        submission.loc[idx, 'proba']=probas.max()    \n",
        "    else:\n",
        "        submission.loc[idx, 'label']=0\n",
        "        submission.loc[idx, 'proba']=probas.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5KKjmibYwDa"
      },
      "source": [
        "Sort the submission with regards to the submission template & save the final submission file to `submission#3.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od8EOLEiYwDa",
        "outputId": "d14492c2-33d4-4225-8d73-4031c33fcbb3"
      },
      "source": [
        "# Download the Phase2 submission template\n",
        "!wget -O submission_format_phase_2.csv  \"https://drivendata-prod.s3.amazonaws.com/data/70/public/submission_format_phase_2.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYVI2LMPSY%2F20201201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201201T023533Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=04330cf22c33f1817cac29509178d2c11a07d620e8237241c5088f4fd25df2b3\"\n",
        "os.chdir(os.path.join(HOME, \"sub3\"))\n",
        "template = pd.read_csv(\"submission_format_phase_2.csv\")\n",
        "# Sort the 'submission' file\n",
        "submission = submission.set_index('id')\n",
        "submission = submission.reindex(index=template['id'])\n",
        "submission = submission.reset_index()\n",
        "# Save submission file\n",
        "submission.to_csv(f\"{HOME}/submission#3.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-01 12:46:36--  https://drivendata-prod.s3.amazonaws.com/data/70/public/submission_format_phase_2.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYVI2LMPSY%2F20201201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201201T023533Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=04330cf22c33f1817cac29509178d2c11a07d620e8237241c5088f4fd25df2b3\n",
            "Resolving drivendata-prod.s3.amazonaws.com (drivendata-prod.s3.amazonaws.com)... 52.216.115.59\n",
            "Connecting to drivendata-prod.s3.amazonaws.com (drivendata-prod.s3.amazonaws.com)|52.216.115.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23807 (23K) [text/csv]\n",
            "Saving to: ‘submission_format_phase_2.csv’\n",
            "\n",
            "\r          submissio   0%[                    ]       0  --.-KB/s               \rsubmission_format_p 100%[===================>]  23.25K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-12-01 12:46:36 (14.2 MB/s) - ‘submission_format_phase_2.csv’ saved [23807/23807]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}